{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-based Web Application develpoment and deployment\n",
    "Estimated Time: 60 minutes\n",
    "\n",
    "#### Overview\n",
    "In this project, we make use of the embedded Watson AI libraries, to create an application that would perform sentiment analysis on a provided text. We then deploy the said application over the web using Flask framework.\n",
    "\n",
    "#### Project guidelines\n",
    "For the completion of this project, you'll have to complete the following 8 tasks, based on the knowledge you have gained through the course.\n",
    "\n",
    "#### Tasks and objectives:\n",
    "* Task 1: Clone the project repository\n",
    "* Task 2: Create a sentiment analysis application using Watson NLP library\n",
    "* Task 3: Format the output of the application\n",
    "* Task 4: Package the application\n",
    "* Task 5: Run Unit tests on your application\n",
    "* Task 6: Deploy as web application using Flask\n",
    "* Task 7: Incorporate Error handling\n",
    "* Task 8: Run static code analysis\n",
    "Let's get started !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About Embeddable Watson AI libraries\n",
    "In this project, you'll be using embeddable libraries to create an AI powered Python application.\n",
    "\n",
    "[Embeddable Watson AI libraries](http://https//www.ibm.com/docs/en/watson-libraries) include the NLP library, the text-to-speech library and the speech-to-text library. These libraries can be embedded and distributed as part of your application. For your convenience, these libraries have been pre-installed on Skills Network Labs Cloud IDE for use in this project.\n",
    "\n",
    "The NLP library includes functions for sentiment analysis, emotion detection, text classification, language detection, etc. among others. The speech-to-text library contains functions that perform the transcription service and generates written text from spoken audio. The text-to-speech library generates natural sounding audio from written text. All available functions, in each of these libraries, calls pretrained AI models that are all available on the Cloud IDE servers, available to all users for free.\n",
    "\n",
    "These libraries may also be accessed through your personal systems. The guidelines for the same are available on the Watson AI library page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Clone the project repository\n",
    "The Github repository of the project is available on the URL mentioned below.\n",
    "\n",
    "`https://github.com/ibm-developer-skills-network/zzrjt-practice-project-emb-ai.git`\n",
    "\n",
    "Clone this GitHub repo, using the Cloud IDE terminal to your project to a folder named `practice_project`. Once the cloning is complete, use the terminal to change the current directory `practice_project`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Create a sentiment analysis application using Watson NLP library\n",
    "NLP sentiment analysis is the practice of using computers to recognize sentiment or emotion expressed in a text. Through NLP, sentiment analysis categorizes words as positive, negative or neutral.\n",
    "\n",
    "Sentiment analysis is often performed on textual data to help businesses monitor brand and product sentiment in customer feedback, and understanding customer needs. It helps attain the attitude and mood of the wider public which can then help gather insightful information about the context.\n",
    "\n",
    "For creating the sentiment analysis application, we'll be making use of the Watson Embedded AI Libraries. Since the functions of these libraries are already deployed on the Cloud IDE server, there is no need of importing these libraries to our code. Instead, we need to send a POST request to the relevant model with the required text and the model will send the appropriate response.\n",
    "\n",
    "A sample code for such an application could be:\n",
    "```\n",
    "import requests\n",
    "\n",
    "def <function_name>(<input_args>):\n",
    "    url = '<relevant_url>'\n",
    "    headers = {<header_dictionary>}\n",
    "    myobj = {<input_dictionary_to_the_function>}\n",
    "    response = requests.post(url, json = myobj, headers=header)\n",
    "    return response.text\n",
    "```\n",
    "\n",
    "**`import requests` comes from `pip3 install requests` so you can run the import local, however it won't work since it does not have watson library installed and the link is only avaliable inside the lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Note: The response of the Watson NLP functions is in the form of an object. For accessing the details of the response, we can use `text` attribute of the object by calling `response.text` and make the function return the response as simple text.*\n",
    "\n",
    "For this project, you'll be using the BERT based Sentiment Analysis function of the Watson NLP Library. For accessing this funciton, the URL, the headers and the input json format is as follows.\n",
    "\n",
    "```\n",
    "URL: 'https://sn-watson-sentiment-bert.labs.skills.network/v1/watson.runtime.nlp.v1/NlpService/SentimentPredict'\n",
    "Headers: {\"grpc-metadata-mm-model-id\": \"sentiment_aggregated-bert-workflow_lang_multi_stock\"}\n",
    "Input json: { \"raw_document\": { \"text\": text_to_analyse } }\n",
    "```\n",
    "\n",
    "Here, `text_to_analyze` is being used as a variable that holds the actual written text which is to be analyzed.\n",
    "\n",
    "In this task, you need to create a file named `sentiment_analysis.py` in `practice_project` folder. In this file, write the function for running sentiment analysis using the Watson NLP BERT Seniment Analysis function, as discussed above. Let us call this function `setiment_analyzer`. Assume that that text to be analysed is passed to the function as an argument and is stored in the variable `text_to_analyse`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Format the output of the application\n",
    "The output of the application created is in the form of a dictionary, but has been formatted as a text. To access relevant pieces of information from this output, we need to first convert this text into a dictionary. Since dictionaries are the default formatting system for JSON files, we make use of the in-built Python library `json`.\n",
    "\n",
    "Let's see how this works.\n",
    "\n",
    "First, in a Python shell, import the json library.\n",
    "`import json`\n",
    "\n",
    "Next, run the sentiment_analyzer function for the text “I love this new technology”, just like in Task 2, and store the output in a variable called `response`.\n",
    "\n",
    "```\n",
    "from sentiment_analysis import sentiment_analyzer\n",
    "response = sentiment_analyzer(\"I love this new technology\")\n",
    "```\n",
    "\n",
    "Now, pass the `response` variable as an argument to the json.loads function and save the output in `formatted_response`. Print `formatted_response` to see the difference in the formatting.\n",
    "\n",
    "```\n",
    "formatted_response = json.loads(response)\n",
    "print(formatted_response)\n",
    "```\n",
    "\n",
    "The expected output of the above mentioned steps is shown in the image below.\n",
    "![how it looks](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0224EN-Coursera/images/jsonify.png)\n",
    "\n",
    "Note that the absence of single quotes on either side on the response indicates that this is no longer a text, but is a dictionary instead. To access the correct information from this dictionary, we need to access the keys appropriately. Since this is a nested dictionary structure, i.e. a dictionary of dictionaries, the following statements need to be used to get the label and the score outputs from this response.\n",
    "\n",
    "```\n",
    "label = formatted_response['documentSentiment']['label']\n",
    "score = formatted_response['documentSentiment']['score']\n",
    "```\n",
    "\n",
    "Check the contents of `label` and `score` to verify the output.\n",
    "![how it looks](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0224EN-Coursera/images/jsonify_check.png)\n",
    "\n",
    "Now, for Task 3, incorporate the above mentioned technique and make changes to the `sentiment_analysis.py` file. The expected output from calling the `seniment_analyzer` function should now be a dictionary with 2 keys, label and score, each having the appropriate value extracted from the response of the Watson NLP function. Verify your changes by testing the modified function in a python shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my code\n",
    "import requests, json\n",
    "\n",
    "def sentiment_analyzer(text_to_analyse):\n",
    "    url = 'https://sn-watson-sentiment-bert.labs.skills.network/v1/watson.runtime.nlp.v1/NlpService/SentimentPredict'\n",
    "    headers = {\"grpc-metadata-mm-model-id\": \"sentiment_aggregated-bert-workflow_lang_multi_stock\"}\n",
    "    myobj =  { \"raw_document\": { \"text\": text_to_analyse } }\n",
    "    response = requests.post(url, json = myobj, headers=headers)\n",
    "    \n",
    "    formatted_response = json.loads(response.text)\n",
    "    label = formatted_response['documentSentiment']['label']\n",
    "    score = formatted_response['documentSentiment']['score']\n",
    "    \n",
    "    return {\"label\": label, \"score\": score}\n",
    "\n",
    "\n",
    "# solution\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def sentiment_analyzer(text_to_analyse):\n",
    "   url = 'https://sn-watson-sentiment-bert.labs.skills.network/v1/watson.runtime.nlp.v1/NlpService/SentimentPredict'\n",
    "   myobj = { \"raw_document\": { \"text\": text_to_analyse } }\n",
    "   header = {\"grpc-metadata-mm-model-id\": \"sentiment_aggregated-bert-workflow_lang_multi_stock\"}\n",
    "   response = requests.post(url, json = myobj, headers=header)\n",
    "   formatted_response = json.loads(response.text)\n",
    "   label = formatted_response['documentSentiment']['label']\n",
    "   score = formatted_response['documentSentiment']['score']\n",
    "   return {'label': label, 'score': score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
