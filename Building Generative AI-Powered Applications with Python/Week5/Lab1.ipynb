{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Chatbot for Your Data\n",
    "\n",
    "In this project, you will create a chatbot for your own pdf file using Flask, a popular web framework, and LangChain, another popular framework for working with large language models (LLMs). The chatbot you develop will not just interact with users through text but also comprehend and answer questions related to the content of a specific document.\n",
    "\n",
    "Click on the demo link below to try the final application that you will create!\n",
    "\n",
    "[**Try the demo app**](https://chatbot-for-own-data.xs6r134s1i6.us-east.codeengine.appdomain.cloud/)\n",
    "\n",
    "At the end of this project, you will gain a deeper understanding of chatbots, web application development using Flask and Python, and the use of LangChain framework in interpreting and responding to a wide array of user inputs. And most important, you would have built a comprehensive and impressive chatbot application!\n",
    "\n",
    "Before you get started, let's look at the key elements you'll be using to build your application.\n",
    "\n",
    "##### Chatbots\n",
    "Chatbots are software applications designed to engage in human-like conversation. They can respond to text inputs from users and are widely used in various domains, including customer service, eCommerce, and education. In this project, you will build a chatbot capable of not only engaging users in a general conversation but also answering queries based on a particular document.\n",
    "\n",
    "##### LangChain\n",
    "LangChain is a versatile tool for building AI-driven language applications. It provides various functionalities such as text retrieval, summarization, translation, and many more, by leveraging pretrained language models. In this project, you will be integrating LangChain into your chatbot, empowering it to understand and respond to diverse user inputs effectively.\n",
    "\n",
    "##### Flask\n",
    "Flask is a lightweight and flexible web framework for Python, known for its simplicity and speed. A web framework is a software framework designed to support the development of web applications, including the creation of web servers, and management of HTTP requests and responses.\n",
    "\n",
    "You will use Flask to create the server side or backend of your chatbot. This involves handling incoming messages from users, processing these messages, and sending appropriate responses back to the user.\n",
    "\n",
    "##### Routes in Flask\n",
    "Routes are an essential part of web development. When your application receives a request from a client (typically a web browser), it needs to know how to handle that request. This is where routing comes in.\n",
    "\n",
    "In Flask, routes are created using the @app.route decorator to bind a function to a URL route. When a user visits that URL, the associated function is executed. In your chatbot project, you will use routes to handle the POST requests carrying user messages and to process document data.\n",
    "\n",
    "#####  - CSS - JavaScript\n",
    "You are provided with a ready-to-use chatbot front-end, built with HTML, CSS, and JavaScript. HTML structures web content, CSS styles it and JavaScript adds interactivity. These technologies create a visually appealing and interactive chatbot interface.\n",
    "\n",
    "### Learning objectives\n",
    "At the end of this project, you will be able to:\n",
    "\n",
    "* Explain the basics of Langchain and AI applications\n",
    "* Set up a development environment for building an assistant using Python Flask\n",
    "* Implement PDF upload functionality to allow the assistant to comprehend file input from users\n",
    "* Integrate the assistant with open source models to give it a high level of intelligence and the ability to understand and respond to user requests\n",
    "* (Optional) Deploy the PDF assistant to a web server for use by a wider audience\n",
    "\n",
    "### Prerequisites\n",
    "Knowledge of the basics of HTML/CSS, JavaScript, and Python is nice to have but not essential. Each step of the process and code will have a comprehensive explanation in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and understanding the user interface\n",
    "\n",
    "In this project, the goal is to create a chatbot with an interface that allows communication.\n",
    "\n",
    "First, let's set up the environment by executing the following code:\n",
    "\n",
    "```\n",
    "pip3 install virtualenv \n",
    "virtualenv my_env # create a virtual environment my_env\n",
    "source my_env/bin/activate # activate my_env\n",
    "```\n",
    "\n",
    "The frontend will use HTML, CSS, and JavaScript. The user interface will be similar to many chatbots you see and use online. The code for the interface is provided and the focus of this guided project is to connect this interface with the backend that handles the uploading of your custom documents and integrates it with an LLM model to get customized responses. The provided code will help you to understand how the frontend and backend interact, and as you go through it, you will learn about the important parts and how it works, giving you a clear understanding of how the frontend works and how to create this simple web page.\n",
    "\n",
    "Run the following commands to retrieve the project, give it an appropriate name, and finally move to that directory by running the following:\n",
    "\n",
    "```\n",
    "git clone https://github.com/sinanazeri/build_own_chatbot_without_open_ai.git\n",
    "mv build_own_chatbot_without_open_ai build_chatbot_for_your_data\n",
    "cd build_chatbot_for_your_data\n",
    "```\n",
    "\n",
    "installing the requirements for the project\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "Have a cup of coffee, it will take 5-10 minutes to install the requirements (You can continue this project while the requirements are installed).\n",
    "\n",
    "The next section gives a brief understanding of how the frontend works.\n",
    "\n",
    "##### HTML, CSS, and JavaScript\n",
    "The `index.html` file is responsible for the layout and structure of the web interface. This file contains the code for incorporating external libraries such as JQuery, Bootstrap, and FontAwesome Icons, and the CSS (`style.css`) and JavaScript code (`script.js`) that control the styling and interactivity of the interface.\n",
    "\n",
    "The `style.css` file is responsible for customizing the visual appearance of the page's components. It also handles the loading animation using CSS keyframes. Keyframes are a way of defining the values of an animation at various points in time, allowing for a smooth transition between different styles and creating dynamic animations.\n",
    "\n",
    "The `script.js` file is responsible for the page's interactivity and functionality. It contains the majority of the code and handles all the necessary functions such as switching between light and dark mode, sending messages, and displaying new messages on the screen. It even enables the users to record audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the worker: Document processing and conversation management worker, part 1\n",
    "\n",
    "`worker.py` is part of a chatbot application that processes user messages and documents. It uses the `langchain` library, which is a Python library for building conversational AI applications. It is responsible for setting up the language model, processing PDF documents into a format that can be used for conversation retrieval, and handling user prompts to generate responses based on the processed documents. Here's a high-level overview of the script:\n",
    "\n",
    "Your task is to fill in the `worker.py` comments with the appropriate code.\n",
    "\n",
    "Let's break down each section in the worker file.\n",
    "The `worker.py` is designed to provide a conversational interface that can answer questions based on the contents of a given PDF document.\n",
    "\n",
    "![img](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0DTPEN/images/document%20processing.jpg)\n",
    "\n",
    "The diagram illustrates the procedure of document processing and information retrieval, seamlessly integrating a large language model (LLM) to facilitate the task of question answering. The whole process happens in `worker.py`. image credit link.\n",
    "\n",
    "1. Initialization init_llm():\n",
    "\n",
    "    * Setting environment variables: The environment variable for the HuggingFace API token is set.\n",
    "    * Loading the language model: The WatsonX language model is initialized with specified parameters.\n",
    "    * Loading embeddings: Embeddings are initialized using a pre-trained model.\n",
    "\n",
    "2. Document processing process_document(document_path):\\\n",
    "    *This function is responsible for processing a given PDF document.*\n",
    "\n",
    "    * Loading the document: The document is loaded using PyPDFLoader.\n",
    "    * Splitting text: The document is split into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "    * Creating embeddings database: An embeddings database is created from the text chunks using Chroma.\n",
    "    * Setting Up the RetrievalQA chain: A RetrievalQA chain is set up to facilitate the question-answering process. This chain uses the initialized language model and the embeddings database to answer questions based on the processed document.\n",
    "\n",
    "3. User prompt processing process_prompt(prompt):\\\n",
    "    *This function processes a user's prompt or question.*\n",
    "    \n",
    "    * Receiving user prompt: The system receives a user prompt (question).\n",
    "    * Querying the model: The model is queried using the retrieval chain, and it generates a response based on the processed document and previous chat history.\n",
    "    * Updating chat history: The chat history is updated with the new prompt and response.\n",
    "\n",
    "#### Delving into each section\n",
    "   *IBM watsonX utilizes various language models, including Llama2 by Meta, which is currently the strongest open-source language model published in Sep 2023.*\n",
    "\n",
    "1. Initialization `init_llm()`:\n",
    "This code is for setting up and using an AI language model, from IBM watsonX:\n",
    "\n",
    "1. **Credentials setup**: Initializes a dictionary with the service URL and an authentication token (`\"skills-network\"`).\n",
    "\n",
    "2. **Parameters configuration**: Sets up model parameters like maximum token generation (`500`) and temperature (`0.1`, controlling randomness).\n",
    "\n",
    "3. **Model initialization**: Creates a model instance with a specific `model_id`, using the credentials and parameters defined above, and specifies `\"skills-network\"` as the project ID.\n",
    "\n",
    "4. **Model usage**: Initializes an interface (`WatsonxLLM`) with the configured model for interaction.\n",
    "\n",
    "This script is specifically configured for a project or environment associated with the “skills-network”.\n",
    "\n",
    "Complete the following code in `worker.py` by inserting the embeddings.\n",
    "\n",
    "In this project, you do not need to specify your own `Watsonx_API` and `Project_id`. You can just specify `project_id=\"skills-network\"` and leave `Watsonx_API` blank.\n",
    "\n",
    "But it's important to note that this access method is exclusive to this Cloud IDE environment. If you are interested in using the model/API outside this environment (e.g., in a local environment), detailed instructions and further information are available in this tutorial.\n",
    "\n",
    "```\n",
    "# placeholder for Watsonx_API and Project_id incase you need to use the code outside this environment\n",
    "Watsonx_API = \"Your WatsonX API\"\n",
    "Project_id= \"Your Project ID\"\n",
    "\n",
    "# Function to initialize the language model and its embeddings\n",
    "def init_llm():\n",
    "    global llm_hub, embeddings\n",
    "\n",
    "    my_credentials = {\n",
    "        \"url\"    : \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "            GenParams.MAX_NEW_TOKENS: 500, # The maximum number of tokens that the model can generate in a single run.\n",
    "            GenParams.TEMPERATURE: 0.1,   # A parameter that controls the randomness of the token generation. A lower value makes the generation more deterministic, while a higher value introduces more randomness.\n",
    "        }\n",
    "\n",
    "\n",
    "    LLAMA2_model = Model(\n",
    "            model_id= 'meta-llama/llama-2-70b-chat', \n",
    "            credentials=my_credentials,\n",
    "            params=params,\n",
    "            project_id=\"skills-network\",  # <--- NOTE: specify \"skills-network\" as your project_id\n",
    "            )\n",
    "\n",
    "    llm_hub = WatsonxLLM(model=LLAMA2_model)\n",
    "\n",
    "    #Initialize embeddings using a pre-trained model to represent the text data.\n",
    "    embeddings =  # create object of Hugging Face Instruct Embeddings with (model_name,  model_kwargs={\"device\": DEVICE} )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
